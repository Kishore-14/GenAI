{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre train Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BME\\llm_workshop\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: What are the symptoms of asthma?\n",
      "\n",
      "A number of symptoms of asthma are common in children and adults. These include:\n",
      "\n",
      "Aching\n",
      "\n",
      "Aching chest\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n",
      "\n",
      "Aching chest pain\n"
     ]
    }
   ],
   "source": [
    "#### Healthcare case studies\n",
    "\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Function to generate answer for a patient question\n",
    "def generate_answer(question):\n",
    "    # Encode the question\n",
    "    input_ids = tokenizer.encode(question, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate answer using GPT-2 model\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=100, num_return_sequences=1, temperature=0.7)\n",
    "    \n",
    "    # Decode the generated answer\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "question = \"What are the symptoms of asthma?\"\n",
    "answer = generate_answer(question)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient Question: symptoms of covid?\n",
      "Generated Answer: Common symptoms of COVID-19 include fever, cough, and shortness of breath.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Sample patient question-answer pairs\n",
    "patient_data = [\n",
    "    {\"question\": \"What are the symptoms of COVID-19?\", \"answer\": \"Common symptoms of COVID-19 include fever, cough, and shortness of breath.\"},\n",
    "    {\"question\": \"How is diabetes diagnosed?\", \"answer\": \"Diabetes is diagnosed through tests such as fasting blood sugar, oral glucose tolerance test, etc.\"},\n",
    "    {\"question\": \"What treatments are available for asthma?\", \"answer\": \"Treatments for asthma include bronchodilators, inhaled corticosteroids, etc.\"},\n",
    "    # Add more patient questions and corresponding answers\n",
    "]\n",
    "\n",
    "# Load pre-trained Sentence Transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "df = pd.DataFrame(patient_data)\n",
    "\n",
    "# Embed the answers\n",
    "answer_embeddings = model.encode(df['answer'], convert_to_tensor=True)\n",
    "\n",
    "def calculate_similarity(query, embeddings):\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(query_embedding, embeddings)[0]\n",
    "    return cos_scores\n",
    "\n",
    "def input_text_model(input_text):\n",
    "    input_sentence_processed = ''.join([i for i in input_text if not i.isdigit()])\n",
    "    query = input_sentence_processed\n",
    "    query_similarity = calculate_similarity(query, answer_embeddings)\n",
    "    top_n = 1\n",
    "    top_indices = query_similarity.argsort().cpu().numpy()[-top_n:]\n",
    "    similar_answers = df.loc[top_indices, 'answer'].tolist()\n",
    "    return similar_answers[-1]\n",
    "\n",
    "# Example usage\n",
    "patient_question = \"symptoms of covid?\"\n",
    "answer = input_text_model(patient_question)\n",
    "print(\"Patient Question:\", patient_question)\n",
    "print(\"Generated Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
